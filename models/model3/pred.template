# Configuration for ImageNet
# Acknowledgement:
#  Ref: http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf
#  The scheduling parameters is adapted from Caffe(http://caffe.berkeleyvision.org/)

pred = %PRED_PATH%
iter = imgbin
  image_list = "../data/test.lst"
  image_bin  = "../data/test.bin"
  image_mean = "models/image_mean.bin"
  crop_x_start = %CROP_X%
  crop_y_start = %CROP_Y%
  min_crop_size=%SZ%
  max_crop_size=%SZ%
  mirror = %FLIP%
iter = threadbuffer
iter = end


eval_train = 1
model_in = ./models/0258.model

task = extract
extract_node_name = top[-1]
output_format = txt

seed = 1989

netconfig=start
layer[0->1] = conv
  kernel_size = 3
  stride = 1
  nchannel = 32
  pad = 1
  random_type = gaussian
  init_sigma = 0.03
layer[1->2] = batch_norm
layer[2->3] = insanity
layer[3->4] = conv
  kernel_size = 3
  stride = 1
  nchannel = 32
  pad = 1
layer[4->5] = insanity
layer[5->6] = max_pooling
  kernel_size = 3
  stride = 2
layer[6->7] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 64
layer[7->8] = batch_norm
layer[8->9] = insanity
layer[9->10] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 64
layer[10->11] = insanity
layer[11->12] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 64
  random_type = gaussian
  init_sigma = 0.031
layer[12->13] = insanity
layer[13->14] = max_pooling
  kernel_size = 3
  stride = 2
layer[14->14.0,15.1] = split
layer[14.0->14.1] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 96
layer[14.1->14.2] = batch_norm
layer[14.2->14.3] = insanity
layer[14.3->14.4] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 96
layer[14.4->14.5] = insanity
layer[14.5->14.6] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 96
layer[14.6->14.7] = insanity
layer[14.7->14.8] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 96
layer[14.8->14.9] = insanity
layer[15.1->15.2] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 96
  random_type = gaussian
  init_sigma = 0.0347
layer[15.2->15.3] = batch_norm
layer[15.3->15.4] = insanity
layer[15.4->15.5] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 96
  random_type = gaussian
  init_sigma = 0.0347
layer[15.5->15.6] = insanity
layer[15.6->15.7] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 96
  random_type = gaussian
  init_sigma = 0.0347
layer[15.7->15.8] = insanity
layer[14.9,15.8->16] = ch_concat
layer[16->17] = max_pooling
  kernel_size = 3
  stride = 3
layer[17->18] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 256
layer[18->19] = batch_norm
layer[19->20] = insanity
layer[20->21] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 256
layer[21->22] = insanity
layer[22->23] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 256
layer[23->24] = insanity
layer[24->25] = conv
  kernel_size = 3
  stride = 1
  pad = 1
  nchannel = 256
  random_type = gaussian
  init_sigma = 0.039
layer[25->26] = insanity
layer[26->27] = conv
  kernel_size = 3
  stride = 1
  nchannel = 256
  random_type = gaussian
  init_sigma = 0.036
layer[27->28,29,30] = split
layer[29->31] = max_pooling
  kernel_size = 2
  stride = 2
layer[30->32] = max_pooling
  kernel_size = 4
  stride = 4
layer[28->33] = flatten
layer[31->34] = flatten
layer[32->35] = flatten
layer[33,34,35->36] = concat
layer[+1] = fullc
  nhidden = 1024
layer[+1] = batch_norm
layer[+1] = insanity
layer[+0] = dropout
  threshold = 0.55
layer[+1] = fullc
  nhidden = 1024
layer[+1] = insanity
layer[+0] = dropout
  threshold = 0.55
layer[+1] = fullc
 nhidden = 121
layer[+0] = softmax
netconfig=end


#insanity
lb = 3
ub = 8
#device
dev = gpu
continue = 1
# evaluation metric
metric = error
metric = logloss
print_step = 1
max_round = 300
num_round = 300
updater = sgd
# input shape not including batch
input_shape = 3,72,72

batch_size = 128
reset_period = 50
# global parameters in any sectiion outside netconfig, and iter
momentum = 0.90
#momentum_schedule = 1
#base_momentum = 0.6
#final_momentum = 0.95
#saturation_epoch = 2500

#maxout = kernel_size = 3, stride = 1, pad = 1 chpool
wmat:lr  = 0.05
wmat:wd  = 0.0005

bias:wd  = 0.000
bias:lr  = 0.1

minimum_lr = 0.00004
# all the learning rate schedule starts with lr
lr:schedule = factor
lr:factor = 0.5
lr:step = 11850

save_model=1
model_dir=models
# random config
random_type = xavier

# new line
