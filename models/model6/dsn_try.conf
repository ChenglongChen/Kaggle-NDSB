# Configuration for ImageNet
# Acknowledgement:
#  Ref: http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf
#  The scheduling parameters is adapted from Caffe(http://caffe.berkeleyvision.org/)


data = train
iter = img
  image_list = "../data/train.lst"
  image_bin  = "../data/train.bin"
  image_mean = "models/image_mean.bin"
  rand_mirror=1
  rand_crop=1
  max_aspect_ratio = 0.5
  max_shear_ratio=0.3
  min_crop_size=60
  max_crop_size=80
  max_rotate_angle=180
  min_random_scale = 0.3
  max_random_scale = 1.8
  min_img_size = 80
  max_img_size = 140
  shuffle=1
iter = threadbuffer
iter = end

#eval = val
#iter = imgbin
#  image_list = "VA.lst"
#  image_bin  = "va.bin"
#  image_mean = "models/image_mean.bin"
#  #mean_value=255,255,255
#  min_crop_size=70
#  max_crop_size=70
#iter = threadbuffer
#iter = end
eval_train = 1

netconfig=start
layer[0->1] = conv
  kernel_size = 3
  stride = 1
  nchannel = 16
layer[1->2] = conv
  kernel_size = 3
  stride = 1
  nchannel = 16
layer[2->3] = insanity
layer[3->4] = max_pooling
  kernel_size = 3
  stride = 1
layer[4->5] = conv
  nchannel = 32
  stride = 2
  kernel_size = 2
  init_bias = 1
  pad = 1
layer[5->6] = insanity
layer[6->7] = conv
  nchannel = 32
  stride = 1
  kernel_size = 2
layer[7->8] = insanity
layer[8->9] = conv
  nchannel = 64
  stride = 1
  kernel_size = 2
  pad = 1
layer[9->10] = insanity
layer[10->11] = conv
  nchannel = 64
  stride = 1
  kernel_size = 2
layer[11->12] = insanity
layer[12->12.1] = conv
  nchannel = 96
  stride = 1
  kernel_size = 2
  pad = 1
layer[12.1->13.1] = insanity
layer[13.1->14.1] = conv
  nchannel = 96
  stride = 1
  kernel_size = 2
layer[14.1->15.1] = insanity
layer[15.1->13.0,14.0] = split
layer[14.0->15.0] = flatten
layer[15.0->16.0] = fullc
  nhidden =121
layer[16.0->16.0] = softmax
  grad_scale = 0.01
layer[13.0->17.0] = max_pooling
  kernel_size = 3
  stride = 1
  pad = 1
#############
layer[17.0->14] = conv
  nchannel = 128
  kernel_size = 2
  stride = 2
  pad = 1
layer[14->15] = insanity
layer[15->16] = conv
  nchannel = 128
  kernel_size = 2
  stride = 1
layer[16->17] = insanity
layer[17->18] = conv
  nchannel = 128
  kernel_size = 2
  stride = 1
  pad = 1
layer[18->19] = insanity
layer[19->20] = conv
  nchannel = 128
  kernel_size = 2
  stride = 1
layer[20->21] = insanity
layer[21->22] = conv
  nchannel = 128
  kernel_size = 2
  stride = 1
  pad = 1
layer[22->23] = insanity
layer[23->24] = conv
  nchannel = 128
  kernel_size = 2
  stride = 1
layer[24->25,26] = split
layer[25->27] = flatten
layer[27->28] = fullc
  nhidden =121
layer[28->28] = softmax
  grad_scale = 0.01
layer[26->29] = max_pooling
  kernel_size = 3
  stride = 1
#############
layer[29->30] = conv
  nchannel = 256
  kernel_size = 2
  stride = 2
  pad = 1
layer[30->31] = insanity
layer[31->32] = conv
  nchannel = 256
  kernel_size = 2
  stride = 1
layer[32->33] = insanity
layer[33->34] = conv
  nchannel = 256
  kernel_size = 2
  stride = 1
  pad = 1
layer[34->35] = insanity
layer[35->36] = conv
  nchannel = 256
  kernel_size = 2
  stride = 1
layer[36->37] = insanity
layer[37->38,39,40] = split
layer[38->41] = max_pooling
  kernel_size = 1
  stride = 1
layer[39->42] = max_pooling
  kernel_size = 3
  stride = 3
layer[40->43] = max_pooling
  kernel_size = 6
  stride = 6
layer[41->44] = flatten
layer[42->45] = flatten
layer[43->46] = flatten
layer[44,45,46->47] = concat
layer[47->47] = dropout
  threshold = 0.5
layer[+1] = fullc
  nhidden = 1024
layer[+1] = insanity
layer[+0] = dropout
  threshold = 0.5
layer[+1] = fullc
  nhidden = 1024
layer[+1] = insanity
layer[+0] = dropout
  threshold = 0.5
layer[+1] = fullc
  nhidden =121
layer[+0] = softmax
netconfig=end
lb = 3
ub = 8
#device
dev = gpu
continue = 0
# evaluation metric
metric = error
metric = logloss
print_step = 1
max_round = 400
num_round = 500
updater = sgd

# input shape not including batch
batch_size = 96
input_shape = 3,70,70

# global parameters in any sectiion outside netconfig, and iter
momentum = 0.9

wmat:lr  = 0.001
wmat:wd  = 0.0005
bias:wd  = 0.000
bias:lr  = 0.002

# all the learning rate schedule starts with lr
lr:schedule = constant
lr:factor = 0.1
lr:step = 100000

save_model=1
model_dir=models
# random config
random_type = xavier
seed=789
seed_data=762

#new line
